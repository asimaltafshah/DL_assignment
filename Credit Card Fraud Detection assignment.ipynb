{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from this link:\n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description about dataset::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
    "\n",
    "\n",
    "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Load Data\n",
    "\n",
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "\n",
    "3.Standardized the Input Variables. \n",
    "\n",
    "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "\n",
    "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "\n",
    "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "\n",
    "7.Train the Model with Epochs (100).\n",
    "\n",
    "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "\n",
    "9.Prediction should be > 92%\n",
    "10.Evaluation Step\n",
    "11Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify fraudulent credit card transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (data.iloc[:, 0:30])\n",
    "y = (data.iloc[:, 30])\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.28571, random_state=42) #0.285*0.7=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "(142403, 30)\n",
      "(85443, 30)\n",
      "(56961, 30)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(10,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4451/4451 [==============================] - 4s 691us/step - loss: 1.2788 - accuracy: 0.9873\n",
      "Epoch 2/100\n",
      "4451/4451 [==============================] - 3s 684us/step - loss: 1.3435 - accuracy: 0.9853\n",
      "Epoch 3/100\n",
      "4451/4451 [==============================] - 3s 699us/step - loss: 1.4898 - accuracy: 0.9840\n",
      "Epoch 4/100\n",
      "4451/4451 [==============================] - 3s 704us/step - loss: 1.0818 - accuracy: 0.9851\n",
      "Epoch 5/100\n",
      "4451/4451 [==============================] - 3s 693us/step - loss: 1.1871 - accuracy: 0.9864\n",
      "Epoch 6/100\n",
      "4451/4451 [==============================] - 3s 692us/step - loss: 1.1797 - accuracy: 0.9850\n",
      "Epoch 7/100\n",
      "4451/4451 [==============================] - 3s 689us/step - loss: 0.9026 - accuracy: 0.9853\n",
      "Epoch 8/100\n",
      "4451/4451 [==============================] - 3s 710us/step - loss: 0.5521 - accuracy: 0.9884\n",
      "Epoch 9/100\n",
      "4451/4451 [==============================] - 3s 697us/step - loss: 0.7840 - accuracy: 0.9860\n",
      "Epoch 10/100\n",
      "4451/4451 [==============================] - 3s 749us/step - loss: 0.7766 - accuracy: 0.9882\n",
      "Epoch 11/100\n",
      "4451/4451 [==============================] - 3s 718us/step - loss: 0.3226 - accuracy: 0.9894\n",
      "Epoch 12/100\n",
      "4451/4451 [==============================] - 4s 818us/step - loss: 0.2180 - accuracy: 0.9916\n",
      "Epoch 13/100\n",
      "4451/4451 [==============================] - 3s 726us/step - loss: 0.1690 - accuracy: 0.9937\n",
      "Epoch 14/100\n",
      "4451/4451 [==============================] - 3s 710us/step - loss: 0.1573 - accuracy: 0.9960\n",
      "Epoch 15/100\n",
      "4451/4451 [==============================] - 3s 706us/step - loss: 0.1441 - accuracy: 0.9976\n",
      "Epoch 16/100\n",
      "4451/4451 [==============================] - 3s 704us/step - loss: 0.1240 - accuracy: 0.9962\n",
      "Epoch 17/100\n",
      "4451/4451 [==============================] - 3s 701us/step - loss: 0.1077 - accuracy: 0.9973\n",
      "Epoch 18/100\n",
      "4451/4451 [==============================] - 3s 723us/step - loss: 0.2877 - accuracy: 0.9951\n",
      "Epoch 19/100\n",
      "4451/4451 [==============================] - 3s 756us/step - loss: 0.1940 - accuracy: 0.9971\n",
      "Epoch 20/100\n",
      "4451/4451 [==============================] - 3s 755us/step - loss: 0.1364 - accuracy: 0.9976\n",
      "Epoch 21/100\n",
      "4451/4451 [==============================] - 3s 766us/step - loss: 0.1778 - accuracy: 0.9968\n",
      "Epoch 22/100\n",
      "4451/4451 [==============================] - 3s 763us/step - loss: 0.1300 - accuracy: 0.9966\n",
      "Epoch 23/100\n",
      "4451/4451 [==============================] - 3s 746us/step - loss: 0.1083 - accuracy: 0.9967\n",
      "Epoch 24/100\n",
      "4451/4451 [==============================] - 3s 748us/step - loss: 0.1355 - accuracy: 0.9974\n",
      "Epoch 25/100\n",
      "4451/4451 [==============================] - 3s 746us/step - loss: 0.1010 - accuracy: 0.9982\n",
      "Epoch 26/100\n",
      "4451/4451 [==============================] - 3s 744us/step - loss: 0.1355 - accuracy: 0.9976\n",
      "Epoch 27/100\n",
      "4451/4451 [==============================] - 3s 754us/step - loss: 0.1491 - accuracy: 0.9969\n",
      "Epoch 28/100\n",
      "4451/4451 [==============================] - 3s 745us/step - loss: 0.0941 - accuracy: 0.9975\n",
      "Epoch 29/100\n",
      "4451/4451 [==============================] - 3s 748us/step - loss: 0.0980 - accuracy: 0.9983\n",
      "Epoch 30/100\n",
      "4451/4451 [==============================] - 4s 833us/step - loss: 0.0462 - accuracy: 0.9980\n",
      "Epoch 31/100\n",
      "4451/4451 [==============================] - 4s 875us/step - loss: 0.0353 - accuracy: 0.9981\n",
      "Epoch 32/100\n",
      "4451/4451 [==============================] - 4s 833us/step - loss: 0.0328 - accuracy: 0.9981\n",
      "Epoch 33/100\n",
      "4451/4451 [==============================] - 3s 750us/step - loss: 0.0333 - accuracy: 0.9982\n",
      "Epoch 34/100\n",
      "4451/4451 [==============================] - 3s 754us/step - loss: 0.0359 - accuracy: 0.9977\n",
      "Epoch 35/100\n",
      "4451/4451 [==============================] - 3s 743us/step - loss: 0.0506 - accuracy: 0.9982\n",
      "Epoch 36/100\n",
      "4451/4451 [==============================] - 3s 771us/step - loss: 0.0845 - accuracy: 0.9978\n",
      "Epoch 37/100\n",
      "4451/4451 [==============================] - 3s 770us/step - loss: 0.0692 - accuracy: 0.9977\n",
      "Epoch 38/100\n",
      "4451/4451 [==============================] - 3s 765us/step - loss: 0.0864 - accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "4451/4451 [==============================] - 3s 774us/step - loss: 0.0824 - accuracy: 0.9980\n",
      "Epoch 40/100\n",
      "4451/4451 [==============================] - 4s 877us/step - loss: 0.1065 - accuracy: 0.9973\n",
      "Epoch 41/100\n",
      "4451/4451 [==============================] - 4s 830us/step - loss: 0.1080 - accuracy: 0.9978\n",
      "Epoch 42/100\n",
      "4451/4451 [==============================] - 3s 767us/step - loss: 0.3167 - accuracy: 0.9981\n",
      "Epoch 43/100\n",
      "4451/4451 [==============================] - 3s 756us/step - loss: 0.1978 - accuracy: 0.9979\n",
      "Epoch 44/100\n",
      "4451/4451 [==============================] - 4s 856us/step - loss: 0.4066 - accuracy: 0.9982\n",
      "Epoch 45/100\n",
      "4451/4451 [==============================] - 4s 965us/step - loss: 0.2028 - accuracy: 0.9982\n",
      "Epoch 46/100\n",
      "4451/4451 [==============================] - 4s 992us/step - loss: 0.0968 - accuracy: 0.9983\n",
      "Epoch 47/100\n",
      "4451/4451 [==============================] - 5s 1ms/step - loss: 0.1549 - accuracy: 0.9983\n",
      "Epoch 48/100\n",
      "4451/4451 [==============================] - 4s 980us/step - loss: 0.0976 - accuracy: 0.9983\n",
      "Epoch 49/100\n",
      "4451/4451 [==============================] - 5s 1ms/step - loss: 0.1138 - accuracy: 0.9983\n",
      "Epoch 50/100\n",
      "4451/4451 [==============================] - 4s 842us/step - loss: 0.0677 - accuracy: 0.9981\n",
      "Epoch 51/100\n",
      "4451/4451 [==============================] - 4s 789us/step - loss: 0.1095 - accuracy: 0.9981\n",
      "Epoch 52/100\n",
      "4451/4451 [==============================] - 4s 813us/step - loss: 0.1037 - accuracy: 0.9982\n",
      "Epoch 53/100\n",
      "4451/4451 [==============================] - 3s 771us/step - loss: 0.0804 - accuracy: 0.9980\n",
      "Epoch 54/100\n",
      "4451/4451 [==============================] - 3s 782us/step - loss: 0.1089 - accuracy: 0.9981\n",
      "Epoch 55/100\n",
      "4451/4451 [==============================] - 4s 799us/step - loss: 0.0969 - accuracy: 0.9981\n",
      "Epoch 56/100\n",
      "4451/4451 [==============================] - 4s 819us/step - loss: 0.0865 - accuracy: 0.9982\n",
      "Epoch 57/100\n",
      "4451/4451 [==============================] - 3s 785us/step - loss: 0.1527 - accuracy: 0.9982\n",
      "Epoch 58/100\n",
      "4451/4451 [==============================] - 4s 796us/step - loss: 0.0960 - accuracy: 0.9979\n",
      "Epoch 59/100\n",
      "4451/4451 [==============================] - 4s 791us/step - loss: 0.0465 - accuracy: 0.9981\n",
      "Epoch 60/100\n",
      "4451/4451 [==============================] - 4s 797us/step - loss: 0.0396 - accuracy: 0.9968\n",
      "Epoch 61/100\n",
      "4451/4451 [==============================] - 3s 786us/step - loss: 0.0763 - accuracy: 0.9972\n",
      "Epoch 62/100\n",
      "4451/4451 [==============================] - 4s 794us/step - loss: 0.0372 - accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "4451/4451 [==============================] - 4s 790us/step - loss: 0.0400 - accuracy: 0.9974\n",
      "Epoch 64/100\n",
      "4451/4451 [==============================] - 4s 806us/step - loss: 0.0424 - accuracy: 0.9977\n",
      "Epoch 65/100\n",
      "4451/4451 [==============================] - 4s 800us/step - loss: 0.0431 - accuracy: 0.9963\n",
      "Epoch 66/100\n",
      "4451/4451 [==============================] - 4s 817us/step - loss: 0.0407 - accuracy: 0.9979\n",
      "Epoch 67/100\n",
      "4451/4451 [==============================] - 4s 888us/step - loss: 0.0306 - accuracy: 0.9978\n",
      "Epoch 68/100\n",
      "4451/4451 [==============================] - 4s 856us/step - loss: 0.0412 - accuracy: 0.9975\n",
      "Epoch 69/100\n",
      "4451/4451 [==============================] - 4s 821us/step - loss: 0.0253 - accuracy: 0.9980\n",
      "Epoch 70/100\n",
      "4451/4451 [==============================] - 4s 806us/step - loss: 0.0302 - accuracy: 0.9972\n",
      "Epoch 71/100\n",
      "4451/4451 [==============================] - 4s 807us/step - loss: 0.0395 - accuracy: 0.9972\n",
      "Epoch 72/100\n",
      "4451/4451 [==============================] - 4s 828us/step - loss: 0.0300 - accuracy: 0.9979\n",
      "Epoch 73/100\n",
      "4451/4451 [==============================] - 4s 836us/step - loss: 0.0407 - accuracy: 0.9975\n",
      "Epoch 74/100\n",
      "4451/4451 [==============================] - 4s 819us/step - loss: 0.0288 - accuracy: 0.9977\n",
      "Epoch 75/100\n",
      "4451/4451 [==============================] - 4s 819us/step - loss: 0.0325 - accuracy: 0.9975\n",
      "Epoch 76/100\n",
      "4451/4451 [==============================] - 4s 834us/step - loss: 0.0642 - accuracy: 0.9968\n",
      "Epoch 77/100\n",
      "4451/4451 [==============================] - 4s 886us/step - loss: 0.0578 - accuracy: 0.9968\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4451/4451 [==============================] - 4s 800us/step - loss: 0.0485 - accuracy: 0.9974\n",
      "Epoch 79/100\n",
      "4451/4451 [==============================] - 4s 856us/step - loss: 0.0381 - accuracy: 0.9969\n",
      "Epoch 80/100\n",
      "4451/4451 [==============================] - 3s 782us/step - loss: 0.0443 - accuracy: 0.9960\n",
      "Epoch 81/100\n",
      "4451/4451 [==============================] - 3s 777us/step - loss: 0.0293 - accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "4451/4451 [==============================] - 4s 788us/step - loss: 0.0274 - accuracy: 0.9982\n",
      "Epoch 83/100\n",
      "4451/4451 [==============================] - 4s 838us/step - loss: 0.0475 - accuracy: 0.9967\n",
      "Epoch 84/100\n",
      "4451/4451 [==============================] - 4s 827us/step - loss: 0.0795 - accuracy: 0.9974\n",
      "Epoch 85/100\n",
      "4451/4451 [==============================] - 4s 955us/step - loss: 0.0348 - accuracy: 0.99800s - loss: 0.0348 - accuracy: 0.99\n",
      "Epoch 86/100\n",
      "4451/4451 [==============================] - 4s 862us/step - loss: 0.0320 - accuracy: 0.9971\n",
      "Epoch 87/100\n",
      "4451/4451 [==============================] - 4s 824us/step - loss: 0.0269 - accuracy: 0.9977\n",
      "Epoch 88/100\n",
      "4451/4451 [==============================] - 4s 843us/step - loss: 0.0357 - accuracy: 0.9971\n",
      "Epoch 89/100\n",
      "4451/4451 [==============================] - 4s 832us/step - loss: 0.0282 - accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "4451/4451 [==============================] - 4s 829us/step - loss: 0.0422 - accuracy: 0.9976\n",
      "Epoch 91/100\n",
      "4451/4451 [==============================] - 4s 829us/step - loss: 0.0510 - accuracy: 0.9969\n",
      "Epoch 92/100\n",
      "4451/4451 [==============================] - 4s 836us/step - loss: 0.0849 - accuracy: 0.9964\n",
      "Epoch 93/100\n",
      "4451/4451 [==============================] - 4s 835us/step - loss: 0.0402 - accuracy: 0.9978\n",
      "Epoch 94/100\n",
      "4451/4451 [==============================] - 4s 839us/step - loss: 0.0427 - accuracy: 0.9975\n",
      "Epoch 95/100\n",
      "4451/4451 [==============================] - 4s 838us/step - loss: 0.0341 - accuracy: 0.9969\n",
      "Epoch 96/100\n",
      "4451/4451 [==============================] - 4s 835us/step - loss: 0.0453 - accuracy: 0.9976\n",
      "Epoch 97/100\n",
      "4451/4451 [==============================] - 4s 844us/step - loss: 0.0859 - accuracy: 0.9968\n",
      "Epoch 98/100\n",
      "4451/4451 [==============================] - 4s 860us/step - loss: 0.0854 - accuracy: 0.9964\n",
      "Epoch 99/100\n",
      "4451/4451 [==============================] - 4s 848us/step - loss: 0.0342 - accuracy: 0.9976\n",
      "Epoch 100/100\n",
      "4451/4451 [==============================] - 4s 895us/step - loss: 0.0490 - accuracy: 0.9971\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict=history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17c838ee160>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc=history_dict['accuracy']\n",
    "\n",
    "epochs=range(1,len(acc)+1)\n",
    "plt.plot(epochs,acc,'b',label='acc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after 25 epoch model become overfil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4451/4451 [==============================] - 4s 688us/step - loss: 54.2280 - accuracy: 0.9435\n",
      "Epoch 2/25\n",
      "4451/4451 [==============================] - 3s 745us/step - loss: 0.9513 - accuracy: 0.9846\n",
      "Epoch 3/25\n",
      "4451/4451 [==============================] - 3s 673us/step - loss: 0.8805 - accuracy: 0.9851\n",
      "Epoch 4/25\n",
      "4451/4451 [==============================] - 3s 702us/step - loss: 0.6522 - accuracy: 0.9866\n",
      "Epoch 5/25\n",
      "4451/4451 [==============================] - 3s 674us/step - loss: 0.6282 - accuracy: 0.9862\n",
      "Epoch 6/25\n",
      "4451/4451 [==============================] - 3s 699us/step - loss: 0.5414 - accuracy: 0.9875\n",
      "Epoch 7/25\n",
      "4451/4451 [==============================] - 3s 753us/step - loss: 0.4787 - accuracy: 0.9873\n",
      "Epoch 8/25\n",
      "4451/4451 [==============================] - 3s 670us/step - loss: 0.2035 - accuracy: 0.9904\n",
      "Epoch 9/25\n",
      "4451/4451 [==============================] - 3s 672us/step - loss: 0.0824 - accuracy: 0.9967\n",
      "Epoch 10/25\n",
      "4451/4451 [==============================] - 3s 679us/step - loss: 0.1454 - accuracy: 0.9953\n",
      "Epoch 11/25\n",
      "4451/4451 [==============================] - 3s 660us/step - loss: 0.1170 - accuracy: 0.9952\n",
      "Epoch 12/25\n",
      "4451/4451 [==============================] - 3s 663us/step - loss: 0.0576 - accuracy: 0.9965\n",
      "Epoch 13/25\n",
      "4451/4451 [==============================] - 3s 726us/step - loss: 0.2773 - accuracy: 0.9916\n",
      "Epoch 14/25\n",
      "4451/4451 [==============================] - 3s 715us/step - loss: 0.0656 - accuracy: 0.9942\n",
      "Epoch 15/25\n",
      "4451/4451 [==============================] - 3s 727us/step - loss: 0.0515 - accuracy: 0.9932\n",
      "Epoch 16/25\n",
      "4451/4451 [==============================] - 3s 760us/step - loss: 0.0623 - accuracy: 0.9961\n",
      "Epoch 17/25\n",
      "4451/4451 [==============================] - 4s 883us/step - loss: 0.0720 - accuracy: 0.9953\n",
      "Epoch 18/25\n",
      "4451/4451 [==============================] - 4s 797us/step - loss: 0.0945 - accuracy: 0.9937\n",
      "Epoch 19/25\n",
      "4451/4451 [==============================] - 4s 818us/step - loss: 0.0460 - accuracy: 0.9957\n",
      "Epoch 20/25\n",
      "4451/4451 [==============================] - 3s 774us/step - loss: 0.0819 - accuracy: 0.9944\n",
      "Epoch 21/25\n",
      "4451/4451 [==============================] - 4s 786us/step - loss: 0.0797 - accuracy: 0.9969\n",
      "Epoch 22/25\n",
      "4451/4451 [==============================] - 3s 712us/step - loss: 0.0827 - accuracy: 0.9957\n",
      "Epoch 23/25\n",
      "4451/4451 [==============================] - 3s 749us/step - loss: 0.0651 - accuracy: 0.9952\n",
      "Epoch 24/25\n",
      "4451/4451 [==============================] - 3s 771us/step - loss: 0.0421 - accuracy: 0.9953\n",
      "Epoch 25/25\n",
      "4451/4451 [==============================] - 3s 759us/step - loss: 0.0647 - accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(10,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history= model.fit(x_train,y_train,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671/2671 [==============================] - 2s 572us/step - loss: 0.0515 - accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "result=model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2571795e-05],\n",
       "       [1.3669818e-18],\n",
       "       [2.7093250e-09],\n",
       "       ...,\n",
       "       [3.0660148e-11],\n",
       "       [3.4069479e-26],\n",
       "       [3.3328123e-13]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
