{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data\n",
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
    "- Shuffle the data if needed.\n",
    "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
    "- Split into 60 and 40 ratio.\n",
    "- Encode labels.\n",
    "- Model : 1 hidden layers including 16 unit.\n",
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "- Train the Model with Epochs (100).\n",
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**\n",
    "- Evaluation Step\n",
    "- Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ionosphere_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature2   351 non-null    int64  \n",
      " 2   feature3   351 non-null    float64\n",
      " 3   feature4   351 non-null    float64\n",
      " 4   feature5   351 non-null    float64\n",
      " 5   feature6   351 non-null    float64\n",
      " 6   feature7   351 non-null    float64\n",
      " 7   feature8   351 non-null    float64\n",
      " 8   feature9   351 non-null    float64\n",
      " 9   feature10  351 non-null    float64\n",
      " 10  feature11  351 non-null    float64\n",
      " 11  feature12  351 non-null    float64\n",
      " 12  feature13  351 non-null    float64\n",
      " 13  feature14  351 non-null    float64\n",
      " 14  feature15  351 non-null    float64\n",
      " 15  feature16  351 non-null    float64\n",
      " 16  feature17  351 non-null    float64\n",
      " 17  feature18  351 non-null    float64\n",
      " 18  feature19  351 non-null    float64\n",
      " 19  feature20  351 non-null    float64\n",
      " 20  feature21  351 non-null    float64\n",
      " 21  feature22  351 non-null    float64\n",
      " 22  feature23  351 non-null    float64\n",
      " 23  feature24  351 non-null    float64\n",
      " 24  feature25  351 non-null    float64\n",
      " 25  feature26  351 non-null    float64\n",
      " 26  feature27  351 non-null    float64\n",
      " 27  feature28  351 non-null    float64\n",
      " 28  feature29  351 non-null    float64\n",
      " 29  feature30  351 non-null    float64\n",
      " 30  feature31  351 non-null    float64\n",
      " 31  feature32  351 non-null    float64\n",
      " 32  feature33  351 non-null    float64\n",
      " 33  feature34  351 non-null    float64\n",
      " 34  label      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0           1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1           1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2           1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3           1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4           1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "346         1         0   0.83508   0.08298   0.73739  -0.14706   0.84349   \n",
       "347         1         0   0.95113   0.00419   0.95183  -0.02723   0.93438   \n",
       "348         1         0   0.94701  -0.00034   0.93207  -0.03227   0.95177   \n",
       "349         1         0   0.90608  -0.01657   0.98122  -0.01989   0.95691   \n",
       "350         1         0   0.84710   0.13533   0.73638  -0.06151   0.87873   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0    -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1    -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2    -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3    -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4    -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "..        ...       ...        ...  ...        ...        ...        ...   \n",
       "346  -0.05567   0.90441   -0.04622  ...   -0.04202    0.83479    0.00123   \n",
       "347  -0.01920   0.94590    0.01606  ...    0.01361    0.93522    0.04925   \n",
       "348  -0.03431   0.95584    0.02446  ...    0.03193    0.92489    0.02542   \n",
       "349  -0.03646   0.85746    0.00110  ...   -0.02099    0.89147   -0.07760   \n",
       "350   0.08260   0.88928   -0.09139  ...   -0.15114    0.81147   -0.04822   \n",
       "\n",
       "     feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0      0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1     -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2      0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3      1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4      0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "346    1.00000    0.12815    0.86660   -0.10714    0.90546   -0.04307      g  \n",
       "347    0.93159    0.08168    0.94066   -0.00035    0.91483    0.04712      g  \n",
       "348    0.92120    0.02242    0.92459    0.00442    0.92697   -0.00577      g  \n",
       "349    0.82983   -0.17238    0.96022   -0.03757    0.87403   -0.16243      g  \n",
       "350    0.78207   -0.00703    0.75747   -0.06678    0.85764   -0.06151      g  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencode = LabelEncoder()\n",
    "data['label']=labelencode.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      1  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      0  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      1  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      0  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (data.iloc[:, 0:34])\n",
    "y = (data.iloc[:, 34])\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.40, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 35)\n",
      "(210, 34)\n",
      "(141, 34)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(16,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 997us/step - loss: 0.9821 - accuracy: 0.2975\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8305 - accuracy: 0.3230\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.7259 - accuracy: 0.4134\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 992us/step - loss: 0.6606 - accuracy: 0.6513\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.6141 - accuracy: 0.8173\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7873\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.5294 - accuracy: 0.7953\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.8299\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.4780 - accuracy: 0.8240\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.7962\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.4787 - accuracy: 0.7947\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.4508 - accuracy: 0.8162\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8543\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8513\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8572\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3757 - accuracy: 0.8829\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8823\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3739 - accuracy: 0.8821\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8859\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3506 - accuracy: 0.8803\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.9040\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8940\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2897 - accuracy: 0.9051\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.9033\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.9314\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.9123\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.9478\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2390 - accuracy: 0.9437\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.9382\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9446\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2324 - accuracy: 0.9308\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9456\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2099 - accuracy: 0.9504\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9358\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9595\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 986us/step - loss: 0.1989 - accuracy: 0.9478\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.9392\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1777 - accuracy: 0.9461\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9566\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9307\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9454\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9609\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9644\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9444\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9578\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9453\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9537\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9654\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9554\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9581\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9808\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9704\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9607\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9577\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9684\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9744\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9704\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9528\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9713\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9678\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9616\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9645\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9641\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9579\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9589\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9503\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9697\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0921 - accuracy: 0.9733\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9812\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9750\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9852\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9789\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.9788\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9875\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.9784\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9888\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9836\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9914\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9921\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9846\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9893\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9929\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 997us/step - loss: 0.0605 - accuracy: 0.9889\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0460 - accuracy: 0.9921\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0570 - accuracy: 0.9825\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0633 - accuracy: 0.9887\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9906\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0486 - accuracy: 0.9887\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9864\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0524 - accuracy: 0.9846\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0698 - accuracy: 0.9838\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0569 - accuracy: 0.9879\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0492 - accuracy: 0.9812\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9805\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0506 - accuracy: 0.9798\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0445 - accuracy: 0.9877\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9817\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0532 - accuracy: 0.9893\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9869\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict=history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19f5fa4dcd0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc=history_dict['accuracy']\n",
    "\n",
    "epochs=range(1,len(loss)+1)\n",
    "plt.plot(epochs,acc,'b',label='acc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after 69 epochs model become overfit (so we train the model till 69 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/69\n",
      "7/7 [==============================] - 1s 997us/step - loss: 0.6691 - accuracy: 0.6701\n",
      "Epoch 2/69\n",
      "7/7 [==============================] - 0s 889us/step - loss: 0.6203 - accuracy: 0.6491\n",
      "Epoch 3/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.6665\n",
      "Epoch 4/69\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.5565 - accuracy: 0.7458\n",
      "Epoch 5/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7228\n",
      "Epoch 6/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7588\n",
      "Epoch 7/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7498\n",
      "Epoch 8/69\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7949\n",
      "Epoch 9/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7986\n",
      "Epoch 10/69\n",
      "7/7 [==============================] - 0s 993us/step - loss: 0.4932 - accuracy: 0.8236\n",
      "Epoch 11/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8144\n",
      "Epoch 12/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.8287\n",
      "Epoch 13/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.8223\n",
      "Epoch 14/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8552\n",
      "Epoch 15/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3917 - accuracy: 0.8696\n",
      "Epoch 16/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.4085 - accuracy: 0.8704\n",
      "Epoch 17/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.3781 - accuracy: 0.8819\n",
      "Epoch 18/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8626\n",
      "Epoch 19/69\n",
      "7/7 [==============================] - 0s 835us/step - loss: 0.3548 - accuracy: 0.8988\n",
      "Epoch 20/69\n",
      "7/7 [==============================] - 0s 987us/step - loss: 0.3625 - accuracy: 0.9106\n",
      "Epoch 21/69\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.3451 - accuracy: 0.9104\n",
      "Epoch 22/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.9354\n",
      "Epoch 23/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.9106\n",
      "Epoch 24/69\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2950 - accuracy: 0.9300\n",
      "Epoch 25/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2735 - accuracy: 0.9412\n",
      "Epoch 26/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2899 - accuracy: 0.9170\n",
      "Epoch 27/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.9117\n",
      "Epoch 28/69\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.2317 - accuracy: 0.9479\n",
      "Epoch 29/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.9313\n",
      "Epoch 30/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2611 - accuracy: 0.9220\n",
      "Epoch 31/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9184\n",
      "Epoch 32/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2527 - accuracy: 0.9197\n",
      "Epoch 33/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.9368\n",
      "Epoch 34/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2013 - accuracy: 0.9365\n",
      "Epoch 35/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9378\n",
      "Epoch 36/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1960 - accuracy: 0.9412\n",
      "Epoch 37/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1839 - accuracy: 0.9510\n",
      "Epoch 38/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9364\n",
      "Epoch 39/69\n",
      "7/7 [==============================] - 0s 837us/step - loss: 0.1846 - accuracy: 0.9341\n",
      "Epoch 40/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1724 - accuracy: 0.9546\n",
      "Epoch 41/69\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1621 - accuracy: 0.9525\n",
      "Epoch 42/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9574\n",
      "Epoch 43/69\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1651 - accuracy: 0.9603\n",
      "Epoch 44/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1504 - accuracy: 0.9631\n",
      "Epoch 45/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9685\n",
      "Epoch 46/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9635\n",
      "Epoch 47/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9523\n",
      "Epoch 48/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1604 - accuracy: 0.9488\n",
      "Epoch 49/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9736\n",
      "Epoch 50/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9701\n",
      "Epoch 51/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1416 - accuracy: 0.9554\n",
      "Epoch 52/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9734\n",
      "Epoch 53/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1212 - accuracy: 0.9642\n",
      "Epoch 54/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9589\n",
      "Epoch 55/69\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1120 - accuracy: 0.9661\n",
      "Epoch 56/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9627\n",
      "Epoch 57/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1074 - accuracy: 0.9676\n",
      "Epoch 58/69\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1086 - accuracy: 0.9736\n",
      "Epoch 59/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9669\n",
      "Epoch 60/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9455\n",
      "Epoch 61/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9736\n",
      "Epoch 62/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1123 - accuracy: 0.9607\n",
      "Epoch 63/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9585\n",
      "Epoch 64/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1240 - accuracy: 0.9505\n",
      "Epoch 65/69\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0919 - accuracy: 0.9598\n",
      "Epoch 66/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9789\n",
      "Epoch 67/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9702\n",
      "Epoch 68/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9592\n",
      "Epoch 69/69\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(16,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history= model.fit(x_train,y_train,epochs=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 748us/step - loss: 0.2240 - accuracy: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22404581308364868, 0.9219858050346375]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.7361302e-01],\n",
       "       [9.8486114e-01],\n",
       "       [9.9808764e-01],\n",
       "       [7.5076711e-01],\n",
       "       [9.7885817e-01],\n",
       "       [9.6034646e-01],\n",
       "       [9.3292314e-01],\n",
       "       [9.9751151e-01],\n",
       "       [9.4648075e-01],\n",
       "       [9.9073774e-01],\n",
       "       [9.6274698e-01],\n",
       "       [8.6584061e-02],\n",
       "       [1.5856326e-02],\n",
       "       [8.6935186e-01],\n",
       "       [9.9350083e-01],\n",
       "       [9.6977615e-01],\n",
       "       [9.9152660e-01],\n",
       "       [6.6869259e-03],\n",
       "       [9.9391741e-01],\n",
       "       [7.3909461e-03],\n",
       "       [9.2669123e-01],\n",
       "       [1.2640744e-02],\n",
       "       [1.7014146e-04],\n",
       "       [9.3732482e-01],\n",
       "       [9.5954454e-01],\n",
       "       [8.2523346e-01],\n",
       "       [2.5475949e-02],\n",
       "       [1.9351929e-02],\n",
       "       [7.4671209e-03],\n",
       "       [9.8729485e-01],\n",
       "       [9.4009590e-01],\n",
       "       [9.8962235e-01],\n",
       "       [9.8577082e-01],\n",
       "       [9.8732388e-01],\n",
       "       [9.9675703e-01],\n",
       "       [5.0108829e-06],\n",
       "       [7.2820669e-01],\n",
       "       [9.8737276e-01],\n",
       "       [8.9293718e-03],\n",
       "       [9.9861330e-01],\n",
       "       [9.9566114e-01],\n",
       "       [9.6611923e-01],\n",
       "       [8.1696260e-01],\n",
       "       [2.2225320e-02],\n",
       "       [9.9611998e-01],\n",
       "       [7.1372002e-02],\n",
       "       [4.7022113e-01],\n",
       "       [9.8572141e-01],\n",
       "       [2.9683489e-01],\n",
       "       [9.9797904e-01],\n",
       "       [9.7490209e-01],\n",
       "       [2.5376558e-02],\n",
       "       [3.2623708e-03],\n",
       "       [8.7823516e-01],\n",
       "       [4.5180917e-03],\n",
       "       [9.4675493e-01],\n",
       "       [9.9055195e-01],\n",
       "       [9.9173820e-01],\n",
       "       [9.7642314e-01],\n",
       "       [8.5018367e-01],\n",
       "       [8.2260140e-06],\n",
       "       [2.6350594e-01],\n",
       "       [4.0962580e-01],\n",
       "       [9.8531330e-01],\n",
       "       [9.8607844e-01],\n",
       "       [7.5341529e-01],\n",
       "       [9.7536576e-01],\n",
       "       [9.8830992e-01],\n",
       "       [9.8206651e-01],\n",
       "       [9.4656789e-01],\n",
       "       [4.3781069e-01],\n",
       "       [9.8680127e-01],\n",
       "       [9.7230709e-01],\n",
       "       [9.9084103e-01],\n",
       "       [9.9266171e-01],\n",
       "       [9.8090327e-01],\n",
       "       [7.4335933e-04],\n",
       "       [3.3890456e-02],\n",
       "       [1.6865849e-02],\n",
       "       [9.9819636e-01],\n",
       "       [9.9444479e-01],\n",
       "       [8.2455778e-01],\n",
       "       [9.9791193e-01],\n",
       "       [9.9367690e-01],\n",
       "       [9.4275349e-01],\n",
       "       [9.8960173e-01],\n",
       "       [9.9071103e-01],\n",
       "       [4.7922432e-03],\n",
       "       [8.0557955e-05],\n",
       "       [5.8386744e-05],\n",
       "       [9.9767911e-01],\n",
       "       [8.1496662e-05],\n",
       "       [5.3149462e-04],\n",
       "       [9.9020743e-01],\n",
       "       [9.9266422e-01],\n",
       "       [9.5006597e-01],\n",
       "       [9.3101215e-01],\n",
       "       [9.6434581e-01],\n",
       "       [9.8853618e-01],\n",
       "       [9.5545638e-01],\n",
       "       [1.7565751e-01],\n",
       "       [9.7407961e-01],\n",
       "       [9.8835462e-01],\n",
       "       [9.9141467e-01],\n",
       "       [5.0592422e-04],\n",
       "       [9.6214986e-01],\n",
       "       [8.8095933e-02],\n",
       "       [9.7525799e-01],\n",
       "       [7.4516815e-01],\n",
       "       [9.6661472e-01],\n",
       "       [2.0341277e-03],\n",
       "       [4.9832234e-01],\n",
       "       [8.1591010e-03],\n",
       "       [6.3163787e-01],\n",
       "       [4.6894422e-01],\n",
       "       [6.0512841e-02],\n",
       "       [9.9184096e-01],\n",
       "       [9.5380187e-01],\n",
       "       [9.5195550e-01],\n",
       "       [9.7759080e-01],\n",
       "       [6.2604547e-03],\n",
       "       [9.9081486e-01],\n",
       "       [9.8793668e-01],\n",
       "       [9.8461527e-01],\n",
       "       [8.9424586e-01],\n",
       "       [2.2687167e-02],\n",
       "       [2.2166073e-03],\n",
       "       [9.5647073e-01],\n",
       "       [9.9614131e-01],\n",
       "       [9.9083775e-01],\n",
       "       [9.8322618e-01],\n",
       "       [3.4072733e-01],\n",
       "       [8.9837086e-01],\n",
       "       [8.4010780e-02],\n",
       "       [9.3388706e-01],\n",
       "       [7.3316944e-01],\n",
       "       [3.2428311e-06],\n",
       "       [9.8052561e-01],\n",
       "       [5.1366933e-06],\n",
       "       [3.5498643e-01],\n",
       "       [7.9673988e-01]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157    1\n",
       "342    1\n",
       "316    1\n",
       "234    0\n",
       "155    1\n",
       "      ..\n",
       "172    0\n",
       "175    1\n",
       "232    0\n",
       "340    1\n",
       "92     1\n",
       "Name: label, Length: 141, dtype: int32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
